---
title: "Data import and tidy data"
date: "2019-10-02"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data import

Working with data provided by R packages is a great way to learn the tools of data science, __but at some point you want to stop learning and start working with your own data__. 
Now you will learn how to read plain-text rectangular files into R.

## readr, readxl and fread

We will have a look at two packages that you will most likely need most in your everyday work: "readr" and "readxl", and as a bonus also fread from "data.table". 

- "readr" package is part of the core tidyverse. readr work on text-based, delimited files.
- "readxl" is also part of the tidyverse. readxl supports both the legacy .xls format and the modern xml-based .xlsx format. There are other R packages for working with excel files. But compared to the other existing packages (e.g. gdata, xlsx, xlsReadWrite) readxl has no external dependencies. Having no external dependencies is a great bonus, considering that Java-dependent packages tend to hit memory limit during importing of large files and you need to deal with it.
- fread() function from data.table package displays (1) superior speed during import (importand when working with large files ~1G+) and (2) guesses delimiter which is important when you have many files from multiple sources with unknown or unexpected column delimiters.

```{r}
library(tidyverse)
```

### readr

Most of readr's functions are concerned with turning flat files into data frames:

- read_csv() reads _comma_ delimited files, 
- read_csv2() reads _semicolon_ separated files (common in countries where , is used as the decimal place), 
- read_tsv() reads _tab_ delimited files, and 
- read_delim() reads in files with _any delimiter_.

The first argument to read_csv() is the most important: it's the path to the file to read.

```{r}
(index <- read_csv(file = "data/viruses.csv"))
```

```{r}
read_csv(file = "data/viruses.csv",col_types = cols(release_date = "c"))
```



When you run read_csv() it prints out a column specification that gives the name and type of each column. That's an important part of readr: http://r4ds.had.co.nz/data-import.html#parsing-a-file

You can also supply an inline csv file. This is useful for experimenting with readr and for creating reproducible examples to share with others:
```{r}
read_csv("a,b,c
1,2,3
4,5,6")
```

Note that string used in the previous example is spread into three lines. You can insert line end/newline explicitly by using "\n" string (no need to leave spaces!): 
```{r}
read_csv("a,b,c\n4,5,6\n1,2,3")
```


Back to column types:
```{r}
read_csv("a,b\n4,2-13-2007", col_types = cols(b = col_date(format = "%m-%d-%Y")))
```


### Skip rows and column names options

In both cases read_csv() uses the first line of the data for the column names, which is a very common convention. There are two cases where you might want to tweak this behaviour:

1. __Sometimes there are a few lines of metadata at the top of the file__. You can use skip = n to skip the first n lines; or use comment = "#" to drop all lines that start with (e.g.) #.

```{r}
(d <- read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3", skip = 2))
```

```{r}
problems(d)
```


```{r}
read_csv("# A comment I want to skip
  x,y,z
  1,2,3", comment = "#")
```

Real-life example:
```{r}
pac <- read_csv2("hf-data/post-acute_care_data_only (rows).csv")
# or use read_delim() with ";" as delimiter
```

```{r}
pac
```

```{r}
my_date_format <- col_date(format = "%d.%m.%Y")
pac <- read_delim("hf-data/post-acute_care_data_only (rows).csv",
                  delim = ";",
          na = "n/a", col_types = cols(invoice_start = my_date_format,
                                  invoice_end = my_date_format))
```


So what's the problem?
```{r}
problems(pac)
```

This real-life example bring us to the another common issue with csv tables:

2. __The data might not have column names__ You can use col_names = FALSE to tell read_csv() not to treat the first row as headings, and instead label them sequentially from X1 to Xn:

In this example, we have only values, with no apparent column names. Note that base R does not allow numeric column names! In base R, read.csv prepends numerics with X and converts to string. read.csv does not allow string input or data, input must be file path.
```{r}
read_csv("1,2,3\n4,5,6", col_names = FALSE)
```

Alternatively you can pass col_names a character vector which will be used as the column names:
```{r}
read_csv("1,2,3\n4,5,6", col_names = c("x","y","z"))
```

Another option that commonly needs tweaking is na: this specifies the value (or values) that are used to represent missing values in your file:
```{r}
read_csv("a,b,c\n1,2,.", na = ".")
```


### Compared to base R

If you've used R before, you might wonder why we're not using read.csv(). There are a few good reasons to favour readr functions over the base equivalents:

- They are typically much faster (~10x) than their base equivalents. Long running jobs have a progress bar, so you can see what's happening. If you're looking for raw speed, try data.table::fread(). It doesn't fit quite so well into the tidyverse, but it can be quite a bit faster.
- They produce tibbles, they don't convert character vectors to factors (use stringsAsFactors = FALSE), use row names, or munge the column names. These are common sources of frustration with the base R functions.

- They are more reproducible. Base R functions inherit some behaviour from your operating system and environment variables, so import code that works on your computer might not work on someone elseâ€™s (eg stringsAsFactors).

### Exercises

1. What function would you use to read a file where fields were separated with
"|"?

2. Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common?

3. What are the most important arguments to read_fwf()?

4. Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like " or '. By convention, read_csv() assumes that the quoting character will be ", and if you want to change it you'll need to use read_delim() instead. What arguments do you need to specify to read the following text into a data frame?

```{r}
"x,y\n1,'a,b'"
```

5. Identify what is wrong with each of the following inline CSV files. What happens when you run the code?
```{r}
read_csv("a,b\n1,2,3\n4,5,6")
read_csv("a,b,c\n1,2\n1,2,3,4")
read_csv("a,b\n\"1")
read_csv("a,b\n1,2\na,b")
read_csv("a;b\n1;3")
```

## readxl
The  package makes it easy to get data out of Excel and into R. Compared to many of the existing packages (e.g. gdata, xlsx, xlsReadWrite) readxl has no external dependencies, so it's easy to install and use on all operating systems. It is designed to work with tabular data.

> readxl supports both the legacy .xls format and the modern xml-based .xlsx format. 

```{r}
library(readxl)
```

Readxl package has two main functions: 

- excel_sheets(): list all sheets in an excel spreadsheet.
- read_excel(): Read xls and xlsx files.
While read_excel() auto detects the format from the file extension, read_xls() and read_xlsx() can be used to read files without extension.

Let's have a look at the sheets:
```{r}
sheets <- excel_sheets("hf-data/post-acute_care_data_only (rows).xlsx")
sheets
```

You need to import one sheet at the time:
```{r}
pac <- read_excel("hf-data/post-acute_care_data_only (rows).xlsx", sheet = "post-acute_care")
pac
```

```{r}
library(lubridate)
start <- ymd("1900-01-01")
start + 39826
```

```{r}
read_excel("hf-data/post-acute_care_data_only (rows).xlsx", sheet = 1)
```

To import multiple sheets, e.g. sheets 3 to 5:
```{r, eval = FALSE}
mft <- map(sheets, ~ read_excel("hf-data/post-acute_care_data_only (rows).xlsx", sheet = .x))
names(mft) <- sheets
bind_rows(mft, .id = "id")
```

## Tidy data

Same underlying data can be can represented in multiple ways: http://r4ds.had.co.nz/tidy-data.html

These are all representations of the same underlying data, but they are not equally easy to use. One dataset, the tidy dataset, will be much easier to work with inside the tidyverse.

There are three interrelated rules which make a dataset tidy:

- Each variable must have its own column.
- Each observation must have its own row.
- Each value must have its own cell.

![Tidy data, figure from r4ds](http://r4ds.had.co.nz/images/tidy-1.png)

These three rules are interrelated because it's impossible to only satisfy two of the three. That interrelationship leads to an even simpler set of practical instructions:

- Put each dataset in a tibble.
- Put each variable in a column.

Why ensure that your data is tidy? There are two main advantages:

There's a general advantage to picking one consistent way of storing data. If you have a __consistent data__ structure, it's easier to learn the tools that work with it because they have an underlying uniformity.

There's a specific advantage to placing variables in columns because it allows __R's vectorised nature__ to shine. As you learned in mutate and summary functions, most built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural.

dplyr, ggplot2, and all the other packages in the tidyverse are designed to work with tidy data. 

## Spreading and gathering

The principles of tidy data seem so obvious that you might wonder if you will ever encounter a dataset that isn't tidy. Unfortunately, however, most data that you will encounter will be untidy. There are two main reasons:

Most people aren't familiar with the principles of tidy data, and it's hard to derive them yourself unless you spend a lot of time working with data.

Data is often organised to facilitate some use other than analysis. For example, data is often organised to make entry as easy as possible.

This means for most real analyses, you'll need to do some tidying. The first step is always to figure out what the variables and observations are. Sometimes this is easy; other times youâ€™ll need to consult with the people who originally generated the data. The second step is to resolve one of two common problems:

- One variable might be spread across multiple columns.

- One observation might be scattered across multiple rows.

Typically a dataset will only suffer from one of these problems; it'll only suffer from both if you're really unlucky! To fix these problems, you'll need the two most important functions in tidyr: gather() and spread().

## Gathering

A common problem is a dataset where some of the column names are not names of variables, but values of a variable. 

```{r}
salary <- read_excel("data/palk.xls", skip = 4)
salary
```
Above table: the column names 2005 etc represent values of the year variable, and each row represents more than one observation, not one.

To tidy a dataset like this, we need to gather those columns into a new pair of variables. To describe that operation we need three parameters:

1. The set of columns that represent values, not variables. In this example, those are the columns starting from 2005.

2. The name of the variable whose values form the column names. I call that the key, and here it is "Aasta" (year).

3. The name of the variable whose values are spread over the cells. I call that value, and here it's the average bruto wage (wage).

Together those parameters generate the call to gather():
```{r}
tidy_salay <- salary %>%
  gather(key = "year", value = "salary", matches("\\d+"))
```
If you are happy with generic column names (in this specific case):
```{r}
salary %>%
  gather()
```


Note that "2005" to "2017" are non-syntactic names (because they donâ€™t start with a letter) so we have to surround them in backticks.


## Spreading

Spreading is the opposite of gathering. You use it when an observation is scattered across multiple rows. For example, take following table: an observation is a month in a year, but each observation is spread across two rows.

```{r}
tidy_salay %>% 
  spread(year, salary)
```

To tidy this up, we first analyse the representation in similar way to gather(). This time, however, we only need two parameters:

1. The column that contains variable names, the key column.

2. The column that contains values forms multiple variables, the value column.


## Separating and uniting

We have one column that contains two variables. To fix this problem, we'll need the separate() function. 

Complement of separate() is unite(), which you use if a single variable is spread across multiple columns.

### Separate

```{r}
viruses <- read_csv("data/viruses.csv")
viruses
```

To separate group variable into 2 columns:
```{r}
viruses %>% 
  separate(col = "group", into = c("type", "type_meta"), sep = ", ")
```

